{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas\n",
    "import torch\n",
    "from interactions import Interactions\n",
    "from cross_validation import random_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "\n",
    "def create_connection():\n",
    "    ctx = snowflake.connector.connect(\n",
    "        user='Zan',\n",
    "        password='Kundalini55!',\n",
    "        account='livenpay.ap-southeast-2')\n",
    "    return ctx\n",
    "\n",
    "def setup_snowflake(cursor):\n",
    "    cursor.execute(\"use warehouse zans_wh\")\n",
    "    cursor.execute(\"use zans_db.postgres\")\n",
    "    \n",
    "def query(cursor,query):\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    return results\n",
    "\n",
    "timestamped_sql = \"\"\"\n",
    "SELECT \n",
    "\taccountcoupon_couponusehistory.time AS \"accountcoupon_couponusehistory.time\",\n",
    "\taccount_localuser.id  AS \"account_localuser.id\",\n",
    "\taccount_localuser.email  AS \"account_localuser.email\",\n",
    "\tmerchant_merchant.name  AS \"merchant_merchant.name\",\n",
    "\tcase when merchant_merchant.membership_zone_id = 1 then 'Melbourne'\n",
    "    when merchant_merchant.membership_zone_id = 2 then 'Sydney'\n",
    "    else null end AS \"merchant_merchant.city\",\n",
    "\tbranch_branch.id  AS \"branch_branch.id\",\n",
    "\tbranch_branch.suburb_id  AS \"branch_branch.suburb_id\"\n",
    "FROM account_localuser AS account_localuser\n",
    "LEFT JOIN accountcoupon_couponusehistory  AS accountcoupon_couponusehistory ON account_localuser.id = accountcoupon_couponusehistory.user_id \n",
    "LEFT JOIN branch_branch  AS branch_branch ON accountcoupon_couponusehistory.branch_id = branch_branch.id \n",
    "LEFT JOIN merchant_merchant  AS merchant_merchant ON merchant_merchant.id = branch_branch.merchant_id \n",
    "\n",
    "WHERE ((CASE WHEN account_localuser.is_staff  THEN 1 ELSE 0 END\n",
    ") = 0) AND ((CASE\n",
    "    WHEN DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())) is not null\n",
    "    AND DATEADD('month', 12, DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE()))) is not null /* date ranges or in the past x days */\n",
    "    THEN\n",
    "    CASE\n",
    "    WHEN accountcoupon_couponusehistory.time >=  TO_TIMESTAMP(DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())))\n",
    "    AND accountcoupon_couponusehistory.time <= TO_TIMESTAMP(DATEADD('month', 12, DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE()))))\n",
    "    THEN 'This Period'\n",
    "    WHEN accountcoupon_couponusehistory.time >=\n",
    "    DATEADD('day',\n",
    "      DATEDIFF('day',\n",
    "        TO_TIMESTAMP(DATEADD('month', 12, DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())))),\n",
    "        TO_TIMESTAMP(DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())))\n",
    "      )*-1,\n",
    "      DATEADD('day', -1,\n",
    "        TO_TIMESTAMP(DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())))\n",
    "      )\n",
    "    )\n",
    "    AND accountcoupon_couponusehistory.time <= TO_TIMESTAMP(DATEADD('day', 1,DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE()))))\n",
    "    THEN 'Previous Period'\n",
    "    END\n",
    "    END\n",
    ") IS NOT NULL\n",
    ")\n",
    "GROUP BY 7,1,2,3,4,5,6\n",
    "ORDER BY 1 DESC\n",
    "\"\"\"\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "\taccount_localuser.id  AS \"account_localuser.id\",\n",
    "\taccount_localuser.email  AS \"account_localuser.email\",\n",
    "\tmerchant_merchant.name  AS \"merchant_merchant.name\",\n",
    "\tcase when merchant_merchant.membership_zone_id = 1 then 'Melbourne'\n",
    "    when merchant_merchant.membership_zone_id = 2 then 'Sydney'\n",
    "    else null end AS \"merchant_merchant.city\",\n",
    "\tbranch_branch.id  AS \"branch_branch.id\",\n",
    "\tbranch_branch.suburb_id  AS \"branch_branch.suburb_id\"\n",
    "FROM account_localuser AS account_localuser\n",
    "LEFT JOIN accountcoupon_couponusehistory  AS accountcoupon_couponusehistory ON account_localuser.id = accountcoupon_couponusehistory.user_id \n",
    "LEFT JOIN branch_branch  AS branch_branch ON accountcoupon_couponusehistory.branch_id = branch_branch.id \n",
    "LEFT JOIN merchant_merchant  AS merchant_merchant ON merchant_merchant.id = branch_branch.merchant_id \n",
    "\n",
    "WHERE ((CASE WHEN account_localuser.is_staff  THEN 1 ELSE 0 END\n",
    ") = 0) AND ((CASE\n",
    "    WHEN DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())) is not null\n",
    "    AND DATEADD('month', 12, DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE()))) is not null /* date ranges or in the past x days */\n",
    "    THEN\n",
    "    CASE\n",
    "    WHEN accountcoupon_couponusehistory.time >=  TO_TIMESTAMP(DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())))\n",
    "    AND accountcoupon_couponusehistory.time <= TO_TIMESTAMP(DATEADD('month', 12, DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE()))))\n",
    "    THEN 'This Period'\n",
    "    WHEN accountcoupon_couponusehistory.time >=\n",
    "    DATEADD('day',\n",
    "      DATEDIFF('day',\n",
    "        TO_TIMESTAMP(DATEADD('month', 12, DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())))),\n",
    "        TO_TIMESTAMP(DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())))\n",
    "      )*-1,\n",
    "      DATEADD('day', -1,\n",
    "        TO_TIMESTAMP(DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE())))\n",
    "      )\n",
    "    )\n",
    "    AND accountcoupon_couponusehistory.time <= TO_TIMESTAMP(DATEADD('day', 1,DATEADD('month', -11, DATE_TRUNC('month', CURRENT_DATE()))))\n",
    "    THEN 'Previous Period'\n",
    "    END\n",
    "    END\n",
    ") IS NOT NULL\n",
    ")\n",
    "GROUP BY 1,2,3,4,5,6\n",
    "ORDER BY 1 DESC\n",
    "\"\"\"\n",
    "\n",
    "ctx = create_connection()\n",
    "cursor = ctx.cursor()\n",
    "setup_snowflake(cursor)\n",
    "\n",
    "TRANSACTIONS = query(cursor,sql)\n",
    "\n",
    "cursor.close()\n",
    "ctx.close()\n",
    "\n",
    "all_data = pd.DataFrame(TRANSACTIONS, columns=['userId','email','merchant','city','branchId','suburb'])\n",
    "#all_data = pd.DataFrame(TRANSACTIONS, columns=['time','userId','email','merchant','city','branchId','suburb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>email</th>\n",
       "      <th>merchant</th>\n",
       "      <th>city</th>\n",
       "      <th>branchId</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366067</td>\n",
       "      <td>bdm@rnjrealty.com.au</td>\n",
       "      <td>Ajisen Ramen</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1482</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366064</td>\n",
       "      <td>preciousngo@hotmail.com</td>\n",
       "      <td>CoCo Fresh Tea &amp; Juice</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1246</td>\n",
       "      <td>418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>366045</td>\n",
       "      <td>elizamcgowan@icloud.com</td>\n",
       "      <td>Messina</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1113</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>366044</td>\n",
       "      <td>ryan@lonstein.net</td>\n",
       "      <td>BL Burgers</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1494</td>\n",
       "      <td>422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>366041</td>\n",
       "      <td>jess.lee.phillips@live.com.au</td>\n",
       "      <td>Oh! Matcha</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1459</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId                          email                merchant    city  \\\n",
       "3   366067           bdm@rnjrealty.com.au            Ajisen Ramen  Sydney   \n",
       "4   366064        preciousngo@hotmail.com  CoCo Fresh Tea & Juice  Sydney   \n",
       "13  366045        elizamcgowan@icloud.com                 Messina  Sydney   \n",
       "14  366044              ryan@lonstein.net              BL Burgers  Sydney   \n",
       "15  366041  jess.lee.phillips@live.com.au              Oh! Matcha  Sydney   \n",
       "\n",
       "    branchId  suburb  \n",
       "3       1482   411.0  \n",
       "4       1246   418.0  \n",
       "13      1113   411.0  \n",
       "14      1494   422.0  \n",
       "15      1459   411.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CITY = \"Sydney\"\n",
    "\n",
    "cull = ['Uber','Secure Parking Melbourne','Taste Of Melbourne','UberEATS Sydney','Liven Bistro'\n",
    "       , 'Cardly - You Write, We Post', 'Good Food & Wine Show', 'Sayers Sister [Kounta Demo]'\n",
    "       , 'Airtasker','Peninsula Hot Springs','Melbourne River Cruises','Grilla House','Margaret River Gourmet Escape','Madeira','Royale Fusion'\n",
    "        ,'The Bar.Ber','Tandoori Point','The Italian Cucina','Tokyo Bar','The Trust'\n",
    "        ,\"Orita's\",'Pelican ','Olive Garden','Golftec','Lash Labs','Cafe on Bourke','Ibuki House','Mint Leaf',\"Tina's Noodle Kitchen\"\n",
    "       ,'Uber Sydney','Cardly - You Write, We Post','Secure Parking Sydney','UberEATS Sydney','Liven Bistro','Good Food & Wine Show','Sayers Sister [Kounta Demo]','Airtasker','Taste Of Sydney']\n",
    "\n",
    "for merchant in cull:\n",
    "    all_data = all_data[all_data.merchant!=merchant]\n",
    "    \n",
    "all_data = all_data.dropna()\n",
    "all_data.branchId = all_data.branchId.astype(int)\n",
    "city_data = all_data[all_data.city==CITY]\n",
    "city_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>branchId</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>365916</td>\n",
       "      <td>1247</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>365916</td>\n",
       "      <td>1458</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>365914</td>\n",
       "      <td>1115</td>\n",
       "      <td>489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>365914</td>\n",
       "      <td>1575</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>365427</td>\n",
       "      <td>1242</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  branchId  suburb\n",
       "66   365916      1247   411.0\n",
       "67   365916      1458   411.0\n",
       "68   365914      1115   489.0\n",
       "69   365914      1575   411.0\n",
       "104  365427      1242   411.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userId,branchId,suburb = city_data['userId'],city_data['branchId'],city_data['suburb']\n",
    "interactions = pd.DataFrame({\"userId\":userId,\"branchId\":branchId,\"suburb\":suburb})\n",
    "interactions = interactions[interactions.groupby('userId').userId.transform(len) > 1]\n",
    "\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "userIds = interactions.userId.unique()\n",
    "itemIds = interactions.branchId.unique()\n",
    "internal_userIds = defaultdict(lambda: len(internal_userIds))\n",
    "internal_itemIds = defaultdict(lambda: len(internal_itemIds))\n",
    "\n",
    "external_userIds = {}\n",
    "external_itemIds = {}\n",
    "\n",
    "for user,item in zip(interactions.userId.values,interactions.branchId.values):\n",
    "    internal_userIds[user]\n",
    "    internal_itemIds[item]\n",
    "    external_userIds[internal_userIds[user]] = user\n",
    "    external_itemIds[internal_itemIds[item]] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>branchId</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>365916</td>\n",
       "      <td>1247</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>365916</td>\n",
       "      <td>1458</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>365914</td>\n",
       "      <td>1115</td>\n",
       "      <td>489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>365914</td>\n",
       "      <td>1575</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>365427</td>\n",
       "      <td>1242</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  branchId  suburb\n",
       "66   365916      1247   411.0\n",
       "67   365916      1458   411.0\n",
       "68   365914      1115   489.0\n",
       "69   365914      1575   411.0\n",
       "104  365427      1242   411.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_proc = interactions\n",
    "\n",
    "internalItems = []\n",
    "internalUsers = []\n",
    "\n",
    "for i,r in interactions.iterrows():\n",
    "    internalItems += [internal_itemIds[int(r.branchId)]]\n",
    "    internalUsers += [internal_userIds[int(r.userId)]]\n",
    "    \n",
    "interactions_proc['branchId'] = internalItems\n",
    "interactions_proc['userId'] = internalUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>branchId</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  branchId  suburb\n",
       "68       1         2   489.0\n",
       "69       1         3   411.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_proc.loc[interactions_proc['userId']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIds = interactions_proc.userId.values\n",
    "itemIds = interactions_proc.branchId.values\n",
    "suburbs = interactions_proc.suburb.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>branchId</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  branchId  suburb\n",
       "66        0         0   411.0\n",
       "67        0         1   411.0\n",
       "68        1         2   489.0\n",
       "69        1         3   411.0\n",
       "104       2         4   411.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDict = {}\n",
    "\n",
    "for i in itemIds:\n",
    "    featureDict[i] = int(interactions_proc.loc[interactions_proc['branchId']==i]['suburb'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = list(featureDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(userIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "feature_interactions = Interactions(userIds,itemIds,item_features=np.asarray(item_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Interactions dataset (13541 users x 314 items x 51182 interactions)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  411.,   411.,   489.,   411.,   411.,   421.,   411.,   418.,\n",
       "         411.,   411.,   411.,   411.,   408.,   408.,   408.,   411.,\n",
       "         411.,   408.,   418.,   408.,   408.,   411.,   411.,   408.,\n",
       "         426.,   411.,   547.,   411.,   411.,   677.,   701.,   411.,\n",
       "         411.,   422.,   411.,   411.,   411.,   408.,   411.,   411.,\n",
       "         422.,   411.,   411.,   411.,   411.,   411.,   453.,   411.,\n",
       "         411.,   526.,   547.,   534.,   411.,   499.,   547.,   678.,\n",
       "         718.,   419.,   419.,   521.,   423.,   408., 16082.,   772.,\n",
       "         419.,   411.,   408.,   772.,   547.,   419.,   419.,   418.,\n",
       "         521.,   411.,   474.,   419.,   419.,   470.,   499.,   411.,\n",
       "         411.,   434.,   408.,   711.,   435.,   892.,   411., 16082.,\n",
       "         411.,   411.,   408.,   411.,   411.,   411.,   411.,   436.,\n",
       "         417.,   411.,   411.,   423.,   411.,   470.,   411.,   446.,\n",
       "         411.,   411.,   411.,   958.,   836.,   411.,   892.,   673.,\n",
       "         419.,   408.,   411.,   431.,   408.,   411.,   712.,   716.,\n",
       "         474.,   421.,   411.,   419.,   411.,   411.,   772.,   411.,\n",
       "         817.,   411.,   423.,   490.,   411.,   411.,   408.,   534.,\n",
       "         417.,   446.,   411.,   411.,   411.,   422.,   411.,   424.,\n",
       "         712.,   419.,   419.,   411.,  2721.,   772.,   411.,   717.,\n",
       "         470.,   449.,   411.,   534.,   411.,   422.,   413.,   436.,\n",
       "         772.,   411.,   716., 16082.,   411.,   411.,   434.,   423.,\n",
       "         422.,   411.,   446.,   446.,   490.,   446.,   411.,   422.,\n",
       "         423.,   499.,   408.,   408., 16082.,   418.,   431.,   462.,\n",
       "         411.,   423.,   423.,   547.,   411.,   498.,   411., 16082.,\n",
       "         426.,   422.,   423.,   423.,   772.,  7623.,   426.,   453.,\n",
       "         423.,   423.,   445.,   902.,   411.,   547.,   616.,   411.,\n",
       "         411.,   493.,   411.,   772.,   408.,   423.,   422.,   423.,\n",
       "         421.,   547.,   423.,   547.,   534.,   446.,   411.,   685.,\n",
       "         411.,   411.,   421.,   436.,   411.,   452.,   408.,   408.,\n",
       "         408.,   411.,   423.,   411.,   422.,   547.,   772.,   748.,\n",
       "         411.,   729.,   411.,   712.,   526.,   409.,   499.,   423.,\n",
       "         411.,   526.,   422.,   490.,   423.,   701.,   470.,   418.,\n",
       "       16082.,   422.,   408.,   411.,   534.,   421.,   438.,   422.,\n",
       "         423.,   547.,   422.,   423.,   701.,   411.,   422.,   499.,\n",
       "         422.,   499.,   616.,   423.,   423.,   926.,   426.,   499.,\n",
       "         421.,   490.,   521.,   534.,   435.,   411.,   501.,   892.,\n",
       "         499.,   446.,   446.,   408.,   408.,   498.,   411.,   616.,\n",
       "         426.,   412.,   408.,   423.,   423.,   547.,   499.,   423.,\n",
       "         489.,   834.,   604.,   434.,   499.,   490.,   411.,   512.,\n",
       "         422.,   446.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_interactions.item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Factorization models for implicit feedback problems.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from helpers import _repr_model\n",
    "from factorization._components import (_predict_process_features,\n",
    "                                                 _predict_process_ids)\n",
    "from losses import (adaptive_hinge_loss,\n",
    "                              bpr_loss,\n",
    "                              hinge_loss,\n",
    "                              pointwise_loss)\n",
    "\n",
    "from factorization.representations import (BilinearNet,\n",
    "                                                     FeatureNet,\n",
    "                                                     HybridContainer)\n",
    "\n",
    "from sampling import sample_items\n",
    "from torch_utils import cpu, gpu, set_seed\n",
    "\n",
    "\n",
    "class ImplicitFactorizationModel(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 loss='pointwise',\n",
    "                 embedding_dim=32,\n",
    "                 n_iter=10,\n",
    "                 batch_size=256,\n",
    "                 l2=0.0,\n",
    "                 learning_rate=1e-2,\n",
    "                 optimizer_func=None,\n",
    "                 use_cuda=False,\n",
    "                 sparse=False,\n",
    "                 random_state=None,\n",
    "                 representation=None,\n",
    "                 n_components=2):\n",
    "\n",
    "        assert loss in ('pointwise',\n",
    "                        'bpr',\n",
    "                        'hinge',\n",
    "                        'adaptive_hinge')\n",
    "\n",
    "        self._loss = loss\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._n_iter = n_iter\n",
    "        self._learning_rate = learning_rate\n",
    "        self._batch_size = batch_size\n",
    "        self._l2 = l2\n",
    "        self._use_cuda = use_cuda\n",
    "        self._sparse = sparse\n",
    "        self._optimizer_func = optimizer_func\n",
    "        self._random_state = random_state or np.random.RandomState()\n",
    "\n",
    "        self._num_users = None\n",
    "        self._num_items = None\n",
    "        self._net = None\n",
    "        self._optimizer = None\n",
    "        self._loss_func = None\n",
    "        self._representation=representation\n",
    "        self._num_components=n_components\n",
    "\n",
    "        set_seed(self._random_state.randint(-10**8, 10**8),\n",
    "                 cuda=self._use_cuda)\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        return _repr_model(self)\n",
    "\n",
    "    @property\n",
    "    def _initialized(self):\n",
    "        return self._net is not None\n",
    "\n",
    "    def _initialize(self, interactions):\n",
    "\n",
    "        (self._num_users,\n",
    "         self._num_items) = (interactions.num_users,\n",
    "                             interactions.num_items)\n",
    "        \n",
    "        if self._representation=='mixture':\n",
    "            latent_net = MixtureNet(self._num_users,\n",
    "                                   self._num_items,\n",
    "                                    self._embedding_dim,\n",
    "                                   num_components=self._num_components)\n",
    "        \n",
    "        elif self._representation=='nonlinear_mixture':\n",
    "            latent_net = NonlinearMixtureNet(self._num_users,\n",
    "                                             self._num_items,\n",
    "                                             self._embedding_dim)\n",
    "            \n",
    "        elif self._representation=='embedding_mixture':\n",
    "            latent_net = EmbeddingMixtureNet(self._num_users,\n",
    "                                            self._num_items,\n",
    "                                            self._embedding_dim)\n",
    "\n",
    "        else:\n",
    "            latent_net = BilinearNet(self._num_users,\n",
    "                                     self._num_items,\n",
    "                                     self._embedding_dim,\n",
    "                                     sparse=self._sparse)\n",
    "            \n",
    "            \n",
    "\n",
    "        if interactions.num_user_features():\n",
    "            user_net = FeatureNet(interactions.num_user_features(),\n",
    "                                  self._embedding_dim)\n",
    "        else:\n",
    "            user_net = None\n",
    "\n",
    "        if interactions.num_context_features():\n",
    "            context_net = FeatureNet(interactions.num_context_features(),\n",
    "                                     self._embedding_dim)\n",
    "        else:\n",
    "            context_net = None\n",
    "\n",
    "        if interactions.num_item_features():\n",
    "            item_net = FeatureNet(interactions.num_item_features(),\n",
    "                                  self._embedding_dim)\n",
    "        else:\n",
    "            item_net = None\n",
    "\n",
    "        self._net = gpu(HybridContainer(latent_net,\n",
    "                                        user_net,\n",
    "                                        context_net,\n",
    "                                        item_net),\n",
    "                        self._use_cuda)\n",
    "\n",
    "        if self._optimizer_func is None:\n",
    "            self._optimizer = optim.Adam(\n",
    "                self._net.parameters(),\n",
    "                weight_decay=self._l2,\n",
    "                lr=self._learning_rate\n",
    "            )\n",
    "        else:\n",
    "            self._optimizer = self._optimizer_func(self._net.parameters())\n",
    "\n",
    "        if self._loss == 'pointwise':\n",
    "            self._loss_func = pointwise_loss\n",
    "        elif self._loss == 'bpr':\n",
    "            self._loss_func = bpr_loss\n",
    "        elif self._loss == 'hinge':\n",
    "            self._loss_func = hinge_loss\n",
    "        else:\n",
    "            self._loss_func = adaptive_hinge_loss\n",
    "\n",
    "    def _check_input(self, user_ids, item_ids, allow_items_none=False):\n",
    "\n",
    "        if isinstance(user_ids, int):\n",
    "            user_id_max = user_ids\n",
    "        else:\n",
    "            user_id_max = user_ids.max()\n",
    "\n",
    "        if user_id_max >= self._num_users:\n",
    "            raise ValueError('Maximum user id greater '\n",
    "                             'than number of users in model.')\n",
    "\n",
    "        if allow_items_none and item_ids is None:\n",
    "            return\n",
    "\n",
    "        if isinstance(item_ids, int):\n",
    "            item_id_max = item_ids\n",
    "        else:\n",
    "            item_id_max = item_ids.max()\n",
    "\n",
    "        if item_id_max >= self._num_items:\n",
    "            raise ValueError('Maximum item id greater '\n",
    "                             'than number of items in model.')\n",
    "\n",
    "    def fit(self, interactions, verbose=False):\n",
    "\n",
    "        user_ids = interactions.user_ids.astype(np.int64)\n",
    "        item_ids = interactions.item_ids.astype(np.int64)\n",
    "\n",
    "        if not self._initialized:\n",
    "            self._initialize(interactions)\n",
    "\n",
    "        self._check_input(user_ids, item_ids)\n",
    "\n",
    "        for epoch_num in range(self._n_iter):\n",
    "\n",
    "            interactions.shuffle(random_state=self._random_state)\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "            for (minibatch_num,\n",
    "                 minibatch) in enumerate(interactions\n",
    "                                         .minibatches(use_cuda=self._use_cuda,\n",
    "                                                      batch_size=self._batch_size)):\n",
    "\n",
    "                minibatch = minibatch.torch(self._use_cuda).variable()\n",
    "\n",
    "                positive_prediction = self._net(minibatch.user_ids,\n",
    "                                                minibatch.item_ids,\n",
    "                                                minibatch.user_features,\n",
    "                                                minibatch.context_features,\n",
    "                                                minibatch.item_features)\n",
    "                \n",
    "                if self._loss == 'adaptive_hinge':\n",
    "                    negative_prediction = [self._get_negative_prediction(minibatch)\n",
    "                                           for _ in range(5)]\n",
    "                else:\n",
    "                    negative_prediction = self._get_negative_prediction(minibatch)\n",
    "\n",
    "                self._optimizer.zero_grad()\n",
    "\n",
    "                loss = self._loss_func(\n",
    "                    positive_prediction,\n",
    "                    negative_prediction,\n",
    "                    weights=minibatch.weights\n",
    "                )\n",
    "\n",
    "                epoch_loss += loss.data[0]\n",
    "\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "\n",
    "            epoch_loss /= minibatch_num + 1\n",
    "\n",
    "            if verbose:\n",
    "                print('Epoch {}: loss {}'.format(epoch_num, epoch_loss))\n",
    "\n",
    "    def _get_negative_prediction(self, minibatch):\n",
    "\n",
    "        negative_items = sample_items(\n",
    "            self._num_items,\n",
    "            len(minibatch),\n",
    "            random_state=self._random_state)\n",
    "        \n",
    "        negative_var = gpu(torch.from_numpy(negative_items), self._use_cuda)\n",
    "\n",
    "        negative_prediction = self._net(minibatch.user_ids,\n",
    "                                        negative_var,\n",
    "                                        minibatch.user_features,\n",
    "                                        minibatch.context_features,\n",
    "                                        minibatch.item_features)\n",
    "\n",
    "        return negative_prediction\n",
    "    \n",
    "    def predict(self, user_ids, item_ids=None,\n",
    "            user_features=None,\n",
    "            context_features=None,\n",
    "            item_features=None):\n",
    "\n",
    "\n",
    "        self._check_input(user_ids, item_ids, allow_items_none=True)\n",
    "        self._net.train(False)\n",
    "\n",
    "        user_ids, item_ids = _predict_process_ids(user_ids, item_ids,\n",
    "                                                  self._num_items,\n",
    "                                                  self._use_cuda)\n",
    "\n",
    "        (user_features,\n",
    "         context_features,\n",
    "         item_features) = _predict_process_features(user_features,\n",
    "                                                    context_features,\n",
    "                                                    item_features,\n",
    "                                                    len(item_ids),\n",
    "                                                    self._use_cuda)\n",
    "\n",
    "        out = self._net(user_ids,\n",
    "                        item_ids,\n",
    "                        user_features,\n",
    "                        context_features,\n",
    "                        item_features)\n",
    "\n",
    "        return cpu(out.data).numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid containers, feature nets, and mixture representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from spotlight.layers import ScaledEmbedding, ZeroEmbedding\n",
    "\n",
    "\"\"\"\n",
    "Classes defining user and item latent representations in\n",
    "factorization models.\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from spotlight.layers import ScaledEmbedding, ZeroEmbedding\n",
    "\n",
    "\n",
    "class HybridContainer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 latent_module,\n",
    "                 user_module=None,\n",
    "                 context_module=None,\n",
    "                 item_module=None):\n",
    "\n",
    "        super(HybridContainer, self).__init__()\n",
    "\n",
    "        self.latent = latent_module\n",
    "        self.user = user_module\n",
    "        self.context = context_module\n",
    "        self.item = item_module\n",
    "\n",
    "    def forward(self, user_ids,\n",
    "                item_ids,\n",
    "                user_features=None,\n",
    "                context_features=None,\n",
    "                item_features=None):\n",
    "\n",
    "        user_representation, user_bias = self.latent.user_representation(user_ids)\n",
    "        item_representation, item_bias = self.latent.item_representation(item_ids)\n",
    "\n",
    "        if self.user is not None:\n",
    "            user_representation += self.user(user_features)\n",
    "        if self.context is not None:\n",
    "            user_representation += self.context(context_features)\n",
    "        if self.item is not None:\n",
    "            item_representation += self.item(item_features)\n",
    "\n",
    "        dot = (user_representation * item_representation).sum(1)\n",
    "\n",
    "        return dot + user_bias + item_bias\n",
    "\n",
    "\n",
    "class FeatureNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, bias=False, nonlinearity='tanh'):\n",
    "\n",
    "        super(FeatureNet, self).__init__()\n",
    "\n",
    "        if nonlinearity == 'tanh':\n",
    "            self.nonlinearity = F.tanh\n",
    "        elif nonlinearity == 'relu':\n",
    "            self.nonlinearity = F.relu\n",
    "        elif nonlinearity == 'sigmoid':\n",
    "            self.nonlinearity = F.sigmoid\n",
    "        elif nonlinearity == 'linear':\n",
    "            self.nonlinearity = lambda x: x\n",
    "        else:\n",
    "            raise ValueError('Nonlineariy must be one of '\n",
    "                             '(tanh, relu, sigmoid, linear)')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.fc_1 = nn.Linear(self.input_dim,\n",
    "                              self.output_dim,\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, features):\n",
    "\n",
    "        return self.nonlinearity(self.fc_1(features))\n",
    "\n",
    "\n",
    "class BilinearNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Bilinear factorization representation.\n",
    "    Encodes both users and items as an embedding layer; the score\n",
    "    for a user-item pair is given by the dot product of the item\n",
    "    and user latent vectors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users: int\n",
    "        Number of users in the model.\n",
    "    num_items: int\n",
    "        Number of items in the model.\n",
    "    embedding_dim: int, optional\n",
    "        Dimensionality of the latent representations.\n",
    "    sparse: boolean, optional\n",
    "        Use sparse gradients.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32, sparse=False):\n",
    "\n",
    "        super(BilinearNet, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.user_embeddings = ScaledEmbedding(num_users, embedding_dim,\n",
    "                                               sparse=sparse)\n",
    "        self.item_embeddings = ScaledEmbedding(num_items, embedding_dim,\n",
    "                                               sparse=sparse)\n",
    "        self.user_biases = ZeroEmbedding(num_users, 1, sparse=sparse)\n",
    "        self.item_biases = ZeroEmbedding(num_items, 1, sparse=sparse)\n",
    "\n",
    "    def user_representation(self, user_ids):\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_ids)\n",
    "        user_embedding = user_embedding.view(-1, self.embedding_dim)\n",
    "\n",
    "        user_bias = self.user_biases(user_ids).view(-1, 1)\n",
    "\n",
    "        return user_embedding, user_bias\n",
    "\n",
    "    def item_representation(self, item_ids):\n",
    "\n",
    "        item_embedding = self.item_embeddings(item_ids)\n",
    "        item_embedding = item_embedding.view(-1, self.embedding_dim)\n",
    "\n",
    "        item_bias = self.item_biases(item_ids).view(-1, 1)\n",
    "\n",
    "        return item_embedding, item_bias\n",
    "\n",
    "    def forward(self, user_representation, user_bias, item_representation, item_bias):\n",
    "        \"\"\"\n",
    "        Compute the forward pass of the representation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_ids: tensor\n",
    "            Tensor of user indices.\n",
    "        item_ids: tensor\n",
    "            Tensor of item indices.\n",
    "        Returns\n",
    "        -------\n",
    "        predictions: tensor\n",
    "            Tensor of predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        dot = (user_representation * item_representation).sum(1)\n",
    "\n",
    "        return dot + user_bias + item_bias\n",
    "\n",
    "class MixtureNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Bilinear factorization representation.\n",
    "    Encodes both users and items as an embedding layer; the score\n",
    "    for a user-item pair is given by the dot product of the item\n",
    "    and user latent vectors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users: int\n",
    "        Number of users in the model.\n",
    "    num_items: int\n",
    "        Number of items in the model.\n",
    "    embedding_dim: int, optional\n",
    "        Dimensionality of the latent representations.\n",
    "    user_embedding_layer: an embedding layer, optional\n",
    "        If supplied, will be used as the user embedding layer\n",
    "        of the network.\n",
    "    item_embedding_layer: an embedding layer, optional\n",
    "        If supplied, will be used as the item embedding layer\n",
    "        of the network.\n",
    "    sparse: boolean, optional\n",
    "        Use sparse gradients.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32,\n",
    "                 projection_scale=1.0,\n",
    "                 num_components=4):\n",
    "\n",
    "        super(MixtureNet, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_components = num_components\n",
    "        self.projection_scale = projection_scale\n",
    "\n",
    "        self.user_embeddings = ScaledEmbedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = ScaledEmbedding(num_items, embedding_dim)\n",
    "\n",
    "        self.user_biases = ZeroEmbedding(num_users, 1)\n",
    "        self.item_biases = ZeroEmbedding(num_items, 1)\n",
    "\n",
    "        self.taste_projection = nn.Linear(embedding_dim,\n",
    "                                          embedding_dim * self.num_components, bias=False)\n",
    "        self.attention_projection = nn.Linear(embedding_dim,\n",
    "                                              embedding_dim * self.num_components, bias=False)\n",
    "\n",
    "        for layer in (self.taste_projection, self.attention_projection):\n",
    "            torch.nn.init.xavier_normal(layer.weight, self.projection_scale)\n",
    "\n",
    "    def user_representation(self, user_ids):\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_ids).squeeze()\n",
    "        user_bias = self.user_biases(user_ids).squeeze()\n",
    "\n",
    "        return user_embedding, user_bias\n",
    "\n",
    "    def item_representation(self, item_ids):\n",
    "\n",
    "        item_embedding = self.item_embeddings(item_ids).squeeze()\n",
    "        item_bias = self.item_biases(item_ids).squeeze()\n",
    "\n",
    "        return item_embedding, item_bias\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_ids)\n",
    "        item_embedding = self.item_embeddings(item_ids)\n",
    "\n",
    "        batch_size, embedding_size = item_embedding.size()\n",
    "\n",
    "        user_tastes = (self.taste_projection(user_embedding)\n",
    "                       .resize(batch_size,\n",
    "                               self.num_components,\n",
    "                               embedding_size))\n",
    "        user_attention = (self.attention_projection(user_embedding)\n",
    "                          .resize(batch_size,\n",
    "                                  self.num_components,\n",
    "                                  embedding_size))\n",
    "        user_attention = user_attention #  * user_embedding.unsqueeze(1).expand_as(user_tastes)\n",
    "\n",
    "        attention = (F.softmax((user_attention *\n",
    "                                item_embedding.unsqueeze(1).expand_as(user_attention))\n",
    "                               .sum(2)).unsqueeze(2).expand_as(user_attention))\n",
    "        weighted_preference = (user_tastes * attention).sum(1)\n",
    "\n",
    "        dot = (weighted_preference * item_embedding).sum(1)\n",
    "\n",
    "        user_bias = self.user_biases(user_ids).squeeze()\n",
    "        item_bias = self.item_biases(item_ids).squeeze()\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            print('User tastes', user_tastes[0][0].abs().mean().data[0])\n",
    "            print('Tastes', weighted_preference.abs().mean().data[0])\n",
    "        #     print('Attention', (user_attention * item_embedding).sum(2).max().data[0])\n",
    "        #     print('Softmax', attention.max(1)[0].mean().data[0])\n",
    "            print('Preference', preference.max(1)[0].mean().data[0])\n",
    "        #     print('Prediction', weighted_preference.mean().data[0])\n",
    "        #     print('Biases', user_bias.max().data[0], item_bias.max().data[0])\n",
    "\n",
    "        return dot + user_bias + item_bias\n",
    "\n",
    "\n",
    "class MixtureComponent(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, num_components):\n",
    "\n",
    "        super(MixtureComponent, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_components = num_components\n",
    "\n",
    "        self.fc_1 = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "        self.fc_2 = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "\n",
    "        self.taste_projection = nn.Linear(embedding_dim,\n",
    "                                          embedding_dim * num_components,\n",
    "                                          bias=False)\n",
    "        self.attention_projection = nn.Linear(embedding_dim,\n",
    "                                              embedding_dim * num_components,\n",
    "                                              bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size, embedding_size = x.size()\n",
    "\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "\n",
    "        user_tastes = (self.taste_projection(x)\n",
    "                       .resize(batch_size,\n",
    "                               self.num_components,\n",
    "                               embedding_size))\n",
    "        user_attention = (self.attention_projection(x)\n",
    "                          .resize(batch_size,\n",
    "                                  self.num_components,\n",
    "                                  embedding_size))\n",
    "\n",
    "        return user_tastes, user_attention\n",
    "\n",
    "\n",
    "class NonlinearMixtureNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Bilinear factorization representation.\n",
    "    Encodes both users and items as an embedding layer; the score\n",
    "    for a user-item pair is given by the dot product of the item\n",
    "    and user latent vectors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users: int\n",
    "        Number of users in the model.\n",
    "    num_items: int\n",
    "        Number of items in the model.\n",
    "    embedding_dim: int, optional\n",
    "        Dimensionality of the latent representations.\n",
    "    user_embedding_layer: an embedding layer, optional\n",
    "        If supplied, will be used as the user embedding layer\n",
    "        of the network.\n",
    "    item_embedding_layer: an embedding layer, optional\n",
    "        If supplied, will be used as the item embedding layer\n",
    "        of the network.\n",
    "    sparse: boolean, optional\n",
    "        Use sparse gradients.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32,\n",
    "                 num_components=4):\n",
    "\n",
    "        super(NonlinearMixtureNet, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_components = num_components\n",
    "\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        self.user_biases = ZeroEmbedding(num_users, 1)\n",
    "        self.item_biases = ZeroEmbedding(num_items, 1)\n",
    "\n",
    "        self.mixture = MixtureComponent(embedding_dim, num_components)\n",
    "        \n",
    "    def user_representation(self, user_ids):\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_ids).squeeze()\n",
    "        user_bias = self.user_biases(user_ids).squeeze()\n",
    "\n",
    "        return user_embedding, user_bias\n",
    "\n",
    "    def item_representation(self, item_ids):\n",
    "\n",
    "        item_embedding = self.item_embeddings(item_ids).squeeze()\n",
    "        item_bias = self.item_biases(item_ids).squeeze()\n",
    "\n",
    "        return item_embedding, item_bias\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Compute the forward pass of the representation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_ids: tensor\n",
    "            Tensor of user indices.\n",
    "        item_ids: tensor\n",
    "            Tensor of item indices.\n",
    "        Returns\n",
    "        -------\n",
    "        predictions: tensor\n",
    "            Tensor of predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_ids)\n",
    "        item_embedding = self.item_embeddings(item_ids)\n",
    "\n",
    "        batch_size, embedding_size = item_embedding.size()\n",
    "\n",
    "        user_tastes, user_attention = self.mixture(user_embedding)\n",
    "        item_embedding = item_embedding.unsqueeze(1).expand_as(user_attention)\n",
    "\n",
    "        attention = F.softmax((user_attention * item_embedding).sum(2))\n",
    "\n",
    "        preference = ((user_tastes * item_embedding)\n",
    "                      .sum(2))\n",
    "        weighted_preference = (attention * preference).sum(1).squeeze()\n",
    "\n",
    "        user_bias = self.user_biases(user_ids).squeeze()\n",
    "        item_bias = self.item_biases(item_ids).squeeze()\n",
    "\n",
    "        return weighted_preference + user_bias + item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:204: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:218: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.5734049677848816\n",
      "Epoch 1: loss 0.28838491439819336\n",
      "Epoch 2: loss 0.16966567933559418\n",
      "Epoch 3: loss 0.12763722240924835\n",
      "Epoch 4: loss 0.10339103639125824\n",
      "Epoch 5: loss 0.09451333433389664\n",
      "Epoch 6: loss 0.08411861211061478\n",
      "Epoch 7: loss 0.0812554657459259\n",
      "Epoch 8: loss 0.076598159968853\n",
      "Epoch 9: loss 0.07150653749704361\n",
      "mean mrr 0.12720720031353022\n"
     ]
    }
   ],
   "source": [
    "train,test = random_train_test_split(feature_interactions)\n",
    "\n",
    "n_tastes = 2\n",
    "\n",
    "model = ImplicitFactorizationModel(n_iter=10,\n",
    "                                   loss='hinge',\n",
    "                                   l2=-1.252542352e-10,\n",
    "                                   representation='mixture',\n",
    "                                  n_components=n_tastes)\n",
    "model.fit(train,verbose=True)\n",
    "\n",
    "\n",
    "from evaluation import mrr_score\n",
    "mrr = mrr_score(model, test)\n",
    "print('mean mrr',mrr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ImplicitFactorizationModel: HybridContainer(\n",
       "  (latent): MixtureNet(\n",
       "    (user_embeddings): ScaledEmbedding(13541, 32)\n",
       "    (item_embeddings): ScaledEmbedding(314, 32)\n",
       "    (user_biases): ZeroEmbedding(13541, 1)\n",
       "    (item_biases): ZeroEmbedding(314, 1)\n",
       "    (taste_projection): Linear(in_features=32, out_features=64, bias=False)\n",
       "    (attention_projection): Linear(in_features=32, out_features=64, bias=False)\n",
       "  )\n",
       "  (item): FeatureNet(\n",
       "    (fc_1): Linear(in_features=314, out_features=32, bias=False)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2818,  0.2358, -0.1447,  0.1530,  0.2601, -0.1392, -0.0484,\n",
      "         -0.1368,  0.2521,  0.1030, -0.1966, -0.2727,  0.1691,  0.1387,\n",
      "         -0.2577,  0.1317, -0.1030,  0.2760,  0.1266,  0.2096,  0.2248,\n",
      "         -0.1078,  0.1155,  0.2455,  0.2426, -0.1097,  0.2501, -0.1546,\n",
      "          0.2178,  0.1011,  0.1746,  0.2147]])\n",
      "tensor([[ 0.1846,  0.3101,  0.0900, -0.2711,  0.9544,  0.7490, -0.6171,\n",
      "         -0.1845,  0.1995, -0.4385, -0.6132, -0.8229,  0.1232,  0.1719,\n",
      "          0.0048, -0.5014,  0.1268,  0.4213, -0.4588,  0.1314, -0.2703,\n",
      "         -0.0272, -0.1857, -0.3243, -0.2580, -0.3034,  0.0146, -0.3015,\n",
      "          0.5201, -0.9172, -0.2361, -0.0938]])\n",
      "tensor([[ 0.]])\n",
      "tensor([[ 2.1021]])\n",
      "tensor([[-0.2309,  0.1621, -0.0111,  0.1826,  0.2127,  0.0141, -0.0356,\n",
      "          0.1589,  0.1389,  0.2627, -0.1116, -0.1009,  0.1247, -0.1725,\n",
      "         -0.1611,  0.0831,  0.0388, -0.0961,  0.0343,  0.0122,  0.0945,\n",
      "          0.2049,  0.0966, -0.1781,  0.4067, -0.0738, -0.1114,  0.1192,\n",
      "          0.0519,  0.1552, -0.0726,  0.2223]])\n",
      "tensor([[-0.0893,  0.0104, -0.2187,  0.0724,  0.2373, -0.0251,  0.1870,\n",
      "          0.1065, -0.2989, -0.0469,  0.0388, -0.2898, -0.1240, -0.1955,\n",
      "         -0.0051,  0.0113,  0.0843,  0.1251, -0.0786,  0.3643, -0.0341,\n",
      "         -0.1016, -0.0482,  0.1387,  0.1132, -0.0813,  0.2001, -0.1004,\n",
      "         -0.0933,  0.0819, -0.0201, -0.1265]])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 4.9565, -5.7202, -3.8930, -5.4087, -2.4766,  5.5210, -1.6496,\n",
      "         -4.6085,  2.9774,  1.5434, -0.8075, -4.1835, -4.3054, -4.3118,\n",
      "          1.6528,  5.7113, -5.8040, -3.1533, -1.2677,  2.6188, -2.5814,\n",
      "         -3.4143,  1.0398, -4.3812, -2.5273, -5.8892, -3.9362,  3.0124,\n",
      "          0.0304,  1.1824,  2.6071, -1.7361, -1.4093, -3.8881, -3.9861,\n",
      "          4.4242,  5.5105, -4.9660,  0.7752, -0.5231, -5.8664, -3.4788,\n",
      "         -4.0619,  5.5936, -4.9290,  1.9058,  5.6279,  4.9252, -0.2843,\n",
      "          1.0495,  1.7215,  3.2429, -3.2034, -3.1542,  6.3533,  5.9589,\n",
      "         -0.4422,  1.5519, -6.4357, -3.7508, -4.1476, -4.5416, -1.1478,\n",
      "          4.1247,  4.3738,  3.4014, -5.9103,  1.1730, -2.2994, -5.5148,\n",
      "          0.1006, -0.7347, -1.7105, -4.0549,  5.8736, -2.2393,  3.1573,\n",
      "          5.9468, -5.7904,  0.2416,  3.1682,  1.0296,  2.0691, -3.4178,\n",
      "          6.2047, -5.1049,  2.4397,  5.1257, -4.3431, -2.9091, -4.2763,\n",
      "          0.0500, -4.3591,  2.7243, -3.9697, -5.8005, -4.8257,  2.5394,\n",
      "          4.2785,  4.5432, -3.5242,  1.1477, -5.7391,  1.7640,  1.7050,\n",
      "         -6.2116,  2.5107, -2.6280, -3.9239, -4.7364,  3.1029, -1.6622,\n",
      "         -6.1082,  0.0653,  2.0712,  5.5578, -0.5419, -1.6505, -5.2107,\n",
      "          4.9414, -5.0799, -2.9226, -4.4685,  2.2674,  6.0354,  4.8926,\n",
      "          0.7238,  6.1558,  2.9356,  1.4561, -2.9571,  4.2943,  0.2515,\n",
      "         -3.6725,  1.8038, -6.0036, -3.5427,  5.7269, -3.3804, -1.1833,\n",
      "         -6.2998, -2.7857,  3.3784, -2.4960,  5.2701,  4.7297, -5.5011,\n",
      "         -1.1854, -0.8508,  6.3515, -1.8164,  6.3792, -3.4775,  1.8443,\n",
      "         -5.0349, -4.6254,  1.9153,  0.1765,  1.1422,  5.7880,  0.9139,\n",
      "          2.1188, -4.2507,  4.5793,  0.0506,  1.3980, -5.1959,  3.8901,\n",
      "         -4.4264, -0.4723,  6.1456,  4.8208,  0.9387,  3.9352,  5.2887,\n",
      "         -1.8675, -1.9245, -1.3745, -0.5497,  3.0496,  1.4374,  0.4546,\n",
      "         -4.8010,  3.6719, -1.0293, -0.7056,  5.0513,  2.4815,  4.9796,\n",
      "          5.3392, -0.8457, -5.3723, -2.1599, -3.9188, -6.4542, -1.7620,\n",
      "         -3.7672, -0.3174,  2.0525, -0.1845,  1.9553,  1.4429,  1.6624,\n",
      "         -5.1907, -0.4852,  2.1616,  2.0995, -0.1137, -4.3615, -0.4879,\n",
      "          1.4005,  6.0159, -0.0237,  2.4238, -5.2219, -3.9770,  3.2365,\n",
      "          0.5563, -3.1543,  1.8584, -0.1020, -1.4569,  3.9573, -4.1310,\n",
      "          4.7650,  3.4248,  2.4647, -5.5376,  5.6720,  6.3260,  0.5985,\n",
      "         -2.7314,  2.2833,  0.9604,  0.7295,  0.9017, -0.4345, -3.8308,\n",
      "         -4.3582,  2.6189, -3.7002,  2.9286,  2.8439,  3.4961, -3.1806,\n",
      "         -5.4724, -2.3870, -1.5988, -5.9585,  4.5685, -5.1590, -2.3191,\n",
      "          5.0283,  5.7422, -5.7274, -2.8324, -3.6748,  0.3637, -4.8287,\n",
      "         -3.7250, -1.1634,  0.3606, -2.3991, -1.1518, -0.3596, -2.4296,\n",
      "         -0.1440,  5.7120, -1.7156,  3.1689, -3.0712, -2.0791, -3.7298,\n",
      "          0.4252,  6.4391,  0.2636, -3.1571, -3.6972, -3.6524,  5.1785,\n",
      "          3.9576,  1.0703,  1.8043, -4.9395,  2.5464, -2.0639,  1.3407,\n",
      "          0.5505,  4.3845,  4.7898,  0.2230, -0.7043, -1.3196, -0.9402,\n",
      "          5.7243,  5.6561,  4.4865, -5.7294,  1.9962, -4.8276, -6.2346,\n",
      "          5.0515, -2.2202, -1.1547, -0.9434,  5.1527,  3.7102,  2.5497,\n",
      "         -2.9986,  6.3426,  1.2941, -0.5372, -0.1856,  5.8271]])\n"
     ]
    }
   ],
   "source": [
    "for i in model._net.parameters():\n",
    "    print(i[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned = list(model._net.parameters())\n",
    "\n",
    "user_embeddings = learned[0]\n",
    "item_embeddings = learned[1]\n",
    "\n",
    "user_embeddings = list(zip(user_embeddings,range(0,feature_interactions.num_users)))\n",
    "item_embeddings = list(zip(item_embeddings,range(0,feature_interactions.num_items)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39993"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_userIds[13495]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {}\n",
    "\n",
    "for emb,u in user_embeddings:\n",
    "    try:\n",
    "        user_dict[external_userIds[u]] = emb\n",
    "    except:\n",
    "        print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict = {}\n",
    "\n",
    "for emb,i in item_embeddings:\n",
    "    try:\n",
    "        item_dict[external_itemIds[i]] = emb\n",
    "    except:\n",
    "        print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1846,  0.3101,  0.0900, -0.2711,  0.9544,  0.7490, -0.6171,\n",
       "         -0.1845,  0.1995, -0.4385, -0.6132, -0.8229,  0.1232,  0.1719,\n",
       "          0.0048, -0.5014,  0.1268,  0.4213, -0.4588,  0.1314, -0.2703,\n",
       "         -0.0272, -0.1857, -0.3243, -0.2580, -0.3034,  0.0146, -0.3015,\n",
       "          0.5201, -0.9172, -0.2361, -0.0938]), 0)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnc = lambda x:x[0]\n",
    "\n",
    "fnc(item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "internalId=2\n",
    "userId=external_userIds[internalId]\n",
    "\n",
    "user = list(zip(range(feature_interactions.num_items),[user_dict[userId].dot(emb) for emb in learned[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = sorted(user,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>email</th>\n",
       "      <th>merchant</th>\n",
       "      <th>city</th>\n",
       "      <th>branchId</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>365427</td>\n",
       "      <td>liqyx@yahoo.com.tw</td>\n",
       "      <td>CoCo Fresh Tea &amp; Juice</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1242</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>365427</td>\n",
       "      <td>liqyx@yahoo.com.tw</td>\n",
       "      <td>Din Tai Fung</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1538</td>\n",
       "      <td>421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>365427</td>\n",
       "      <td>liqyx@yahoo.com.tw</td>\n",
       "      <td>Tontaro Ramen</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1588</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId               email                merchant    city  branchId  \\\n",
       "104  365427  liqyx@yahoo.com.tw  CoCo Fresh Tea & Juice  Sydney      1242   \n",
       "105  365427  liqyx@yahoo.com.tw            Din Tai Fung  Sydney      1538   \n",
       "106  365427  liqyx@yahoo.com.tw           Tontaro Ramen  Sydney      1588   \n",
       "\n",
       "     suburb  \n",
       "104   411.0  \n",
       "105   421.0  \n",
       "106   411.0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_data[city_data['userId']==userId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9755)  ------  Tontaro Ramen :  411.0\n",
      "tensor(3.7341)  ------  Din Tai Fung :  421.0\n",
      "tensor(3.6773)  ------  Din Tai Fung :  958.0\n",
      "tensor(3.0674)  ------  Eat Fuh :  892.0\n",
      "tensor(2.9645)  ------  YiFang Taiwan Fruit Tea :  411.0\n",
      "tensor(2.8739)  ------  TNS Coffee Project :  419.0\n",
      "tensor(2.8434)  ------  CoCo Fresh Tea & Juice :  411.0\n",
      "tensor(2.8253)  ------  CoCo Fresh Tea & Juice :  408.0\n",
      "tensor(2.8113)  ------  Din Tai Fung :  526.0\n",
      "tensor(2.8028)  ------  Sharetea :  411.0\n",
      "tensor(2.7719)  ------  Meet Fresh :  408.0\n",
      "tensor(2.6199)  ------  CoCo Fresh Tea & Juice :  418.0\n",
      "tensor(2.6175)  ------  Bubble Nini Tea :  419.0\n",
      "tensor(2.4962)  ------  Ajisen Ramen :  411.0\n",
      "tensor(2.4537)  ------  CoCo Fresh Tea & Juice :  411.0\n",
      "tensor(2.4278)  ------  Enjoy Cafe by Enjoy Mie :  411.0\n",
      "tensor(2.4030)  ------  CoCo Fresh Tea & Juice :  435.0\n",
      "tensor(2.1336)  ------  CoCo Fresh Tea & Juice :  418.0\n",
      "tensor(2.1095)  ------  Oh! Matcha :  411.0\n",
      "tensor(2.0526)  ------  SumoSalad :  716.0\n"
     ]
    }
   ],
   "source": [
    "preds = sorted(user,key=lambda x:x[1],reverse=True)\n",
    "\n",
    "for i in range(20):\n",
    "    branchId = external_itemIds[preds[i][0]]\n",
    "    x = city_data[city_data['branchId']==branchId]\n",
    "    merchant = x.merchant.unique()\n",
    "    suburb = x.suburb.unique()\n",
    "    print(preds[i][1],' ------ ',merchant[0],': ',str(suburb[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2309,  0.1621, -0.0111,  ...,  0.1552, -0.0726,  0.2223],\n",
      "        [-0.1488, -0.1038, -0.2354,  ...,  0.1795, -0.2043, -0.2836],\n",
      "        [ 0.0858,  0.1737, -0.0180,  ...,  0.1713,  0.2585, -0.0894],\n",
      "        ...,\n",
      "        [-0.0351,  0.1418,  0.1889,  ...,  0.3052, -0.0912,  0.2476],\n",
      "        [-0.0448, -0.1151,  0.1705,  ...,  0.0301, -0.0131,  0.0723],\n",
      "        [ 0.0954,  0.0016,  0.0554,  ...,  0.1327,  0.1234,  0.0061]])\n",
      "tensor([[ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "taste_projection = nn.Linear(32,32 * n_tastes, bias=False)\n",
    "print(learned[4])\n",
    "taste_projection.weight = learned[4]\n",
    "print(taste_projection.weight==learned[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "tastes = taste_projection(user_dict[userId]).resize(n_tastes,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1257, -0.6785,  0.4028,  0.6221,  0.1428, -0.0869, -0.2074,\n",
       "         -0.0290,  0.1835,  0.5776,  0.1427,  0.6573, -0.2319, -0.0322,\n",
       "          0.4825,  0.3988, -0.4860,  0.0883,  0.8176,  0.3656,  0.2747,\n",
       "          0.1157, -0.3219, -0.2323, -0.2095, -0.4324,  0.2579, -0.3439,\n",
       "          0.5007, -0.3284,  0.4328, -0.1140],\n",
       "        [ 0.1175,  0.2679,  0.1728, -0.1262,  0.7739,  0.5620, -0.4101,\n",
       "         -0.0028,  0.0390,  0.0554, -0.3447,  0.3714, -0.1323,  0.1399,\n",
       "         -0.0456, -0.7780,  0.3907, -0.3821, -0.5116, -0.0446, -0.1088,\n",
       "         -0.6998,  0.0186, -0.0162, -0.5486,  0.0920, -0.3349,  0.0504,\n",
       "          0.0360, -0.7610,  0.2625, -0.3747]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tastes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for taste in tastes:\n",
    "    preds+=[list(zip(range(feature_interactions.num_items),[taste.dot(emb) for emb in learned[1]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taste profile:  1\n",
      "tensor(3.3222)  ------  Two Sticks :  16082.0\n",
      "tensor(3.1065)  ------  Mr Bao :  411.0\n",
      "tensor(3.0644)  ------  PappaRich :  411.0\n",
      "tensor(2.7762)  ------  YiFang Taiwan Fruit Tea :  521.0\n",
      "tensor(2.7562)  ------  New Shanghai :  547.0\n",
      "tensor(2.7202)  ------  La Lucha :  411.0\n",
      "tensor(2.6394)  ------  Nama :  411.0\n",
      "tensor(2.6201)  ------  Treetop Cafe :  435.0\n",
      "tensor(2.5574)  ------  85 Degrees Cafe :  411.0\n",
      "tensor(2.4985)  ------  Naya Cafe :  490.0\n",
      "\n",
      "\n",
      "Taste profile:  2\n",
      "tensor(3.6199)  ------  Sharetea :  677.0\n",
      "tensor(2.8677)  ------  Sexy Tea :  408.0\n",
      "tensor(2.8057)  ------  CoCo Fresh Tea & Juice :  411.0\n",
      "tensor(2.7598)  ------  Pasta Pantry :  411.0\n",
      "tensor(2.7013)  ------  Sushi Rap :  411.0\n",
      "tensor(2.4968)  ------  Shinsen Sushi :  411.0\n",
      "tensor(2.3899)  ------  Aqua S :  411.0\n",
      "tensor(2.2000)  ------  Sharetea :  474.0\n",
      "tensor(2.1627)  ------  Ho Jiak :  718.0\n",
      "tensor(2.0887)  ------  Oh! Matcha :  411.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for recs in preds:\n",
    "    recs = sorted(recs,key=lambda x:x[1],reverse=True)\n",
    "    count += 1\n",
    "    print('Taste profile: ',count)\n",
    "    for i in range(10):\n",
    "        branchId = external_itemIds[recs[i][0]]\n",
    "        x = city_data[city_data['branchId']==branchId]\n",
    "        merchant = x.merchant.unique()\n",
    "        suburb = x.suburb.unique()\n",
    "        print(recs[i][1],' ------ ',merchant[0],': ',str(suburb[0]))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
